{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmBC0EC/WC3Qo8QuPLGXf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pattangeumdduck/stack_study_record/blob/main/aice_professionalstudy_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이미지 Dataset 만들기 - glob과 Dataset from_tensor_slices활용하기\n",
        "- 콘크리트 이미지 데이터를 가지고 모델 학습에 사용할 데이터셋을 만들어 이미지 분류 실습\n",
        "- 우선, 콘크리트 이미지 데이터(깨진 콘크리트와 안깨진 콘크리트 데이터)를 glob, from_tensor_slices, Pipeline을 활용해서 Dataset만들기\n",
        "- 그리고, 모델 학습하기 위해서는 Dataset 뿐 아니라 라벨정보도 필요하므로 라벨정보도 포함되도록 dataset만들고 이를 이용해 모델을 구축해보기\n",
        "\n",
        "#학습목차\n",
        "A. 이미지 데이터셋 만들기(라벨 정보 없음)\n",
        "1. 필요한 라이브러리 임포트\n",
        "2. 이미지 파일 가져오기 :concrete_image.zip\n",
        "3. 이미지 파일 하나 읽어 이미지보기\n",
        "4. glob과 from_tensor_slices, Pipeline 이용하여 이미지 데이터셋 만들기\n",
        "\n",
        "B. 라벨정보 포함한 이미지 데이터셋 만들기(많은 수작업 필요)\n",
        "1. glob이용하여 이미지 패스 읽기\n",
        "2. shuffle\n",
        "3. Train/ Test용 나누기\n",
        "4. 이미지 라벨링 만들기\n",
        "5. from_tensor_slices >map > cache > batch > shuffle > prefetch 이미지/라벨링 데이터셋 만들기\n",
        "\n",
        "C. Build Model\n",
        "1. Build Model\n",
        "2. Callback\n",
        "3. 모델학습\n",
        "4. 성능 그래프\n",
        "5. predict\n",
        "\n"
      ],
      "metadata": {
        "id": "mTjpAa-7-BQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터셋 만들기(라벨 정보 없이)\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NbcGkKZN-A3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dSS-hQB9ooD",
        "outputId": "b1c2a931-55d7-4a3b-fa93-5ef5414603f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#이미지 파일 가져오기 :concrete_image.zip\n",
        "glob('concrete_image.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 폴더 생성 및 concrete_image.zip 파일 압축 풀기 > 3000개 이미지로 실습을 위해 데이터 축소.\n",
        "\n",
        "if not os.path.exists('IMAGE'):\n",
        "  os.mkdir('IMAGE')\n",
        "  !unzip concrete_imagez.zip -d IMAGE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qXI_KX6BGPU",
        "outputId": "4366a64b-e976-4be5-85bc-a803eaa6b011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open concrete_imagez.zip, concrete_imagez.zip.zip or concrete_imagez.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concrete_image Negative 폴더 안의 이미지 갯수\n",
        "!ls -1 ./IMAGE/Negative/ | grep jpg | wc -1\n",
        "\n",
        "#concrete_image Positive폴더 안의 이미지 갯수\n",
        "!ls -1 ./IMAGE/Positive/ | grep jpg | wc -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZcwlISbBgCH",
        "outputId": "4ea3999f-a726-4d6d-e674-c025e8f2968c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './IMAGE/Negative/': No such file or directory\n",
            "wc: invalid option -- '1'\n",
            "Try 'wc --help' for more information.\n",
            "wc: invalid option -- '1'\n",
            "Try 'wc --help' for more information.\n",
            "ls: cannot access './IMAGE/Positive/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 파일 하나 읽어 이미지 보기\n",
        "#이미지 패스 지정\n",
        "path = './IMAGE/Negative/00001.jpg'"
      ],
      "metadata": {
        "id": "bzndTfW6B98q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 읽어오기\n",
        "gfile = tf.io.read_file(path)\n",
        "iage = tf.io.decode_image(gfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "XaB6LYM1CKV1",
        "outputId": "e7b1c00b-d50a-456b-e5c9-7ea66b70cdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "{{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./IMAGE/Negative/00001.jpg; No such file or directory [Op:ReadFile]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2608298179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#이미지 읽어오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0miage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    581\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       return read_file_eager_fallback(\n\u001b[0m\u001b[1;32m    584\u001b[0m           filename, name=name, ctx=_ctx)\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    604\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m    607\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./IMAGE/Negative/00001.jpg; No such file or directory [Op:ReadFile]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #이미지 shape 확ㅇㄴ\n",
        " image.shape\n",
        " #읽어온 이미지 보기\n",
        " plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Go7eTDt7CUwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#glob과 from_tensor_slices, Pipeline 이용하여 이미지 데이터셋 만들기\n",
        "#glob 활용하여 이미지 패스를 만든다/\n",
        "#glob결과로 리스트를 리턴함\n",
        "image_paths = glob('./IMAGE/*/*.jpg')\n",
        "\n",
        "print(len(image_paths))\n",
        "print(image_paths[-10:])"
      ],
      "metadata": {
        "id": "7INUa1WsCspr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 패스를 주면 이미지 읽고 반환하는 함수\n",
        "def read_image(path):\n",
        "  gfile = tf.io.read_file(path)\n",
        "  image = tf.io.decode_image(gfile)\n",
        "  return image"
      ],
      "metadata": {
        "id": "bwV_q5MQs0Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#병렬화\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "MiFtBOptsxm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 패스리스트를 from tensor slices 사용해 데이터셋 만들고\n",
        "#map 함수를 사용하여 각 이미지 패스의 이미지들을 병렬로 읽어오기\n",
        "dataset = tf.data.Datasets.from_tensor_slices(images_paths)\n",
        "dataset = dataset.map(read_image, num_paralel_callse=AUTOTUNE)"
      ],
      "metadata": {
        "id": "PQ7T0M9cs8on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋에서 1개 이미지 가져오기\n",
        "tf_image = next(iter(dataset))\n",
        "tf_image.shape"
      ],
      "metadata": {
        "id": "Hcmd8eHvtS7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Negative 데이터 샘플\n",
        "plt.imshow(tf_image)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "noLykmr0tc1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 패스의 이미지 읽고(map) 4개 배치 묶기\n",
        "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "dataset = dataset.map(read_image)\n",
        "dataset = dataset.batch(4)"
      ],
      "metadata": {
        "id": "t55rGYLctlje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Negative 데이터 샘플들\n",
        "for i in range(4):\n",
        "  plt.imshow(tf_images[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1BM3z0pzuLPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from_tensor_slices > map > cache > batch > shuffle > prefetch 형태로 사용\n",
        "dataset = tf.data.Dataset.from_tensor_slices(image_paths) #입력 :이미지 패스 리스트\n",
        "dataset = dataset.map(read_image, num_parallel_calls=AUTOTUNE) #이미지 패스의 각 이미지 읽기\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.batch(4)\n",
        "dataset = dataset.shuffle(buffer_size=512)\n",
        "dataset = dataset.prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "vIfnpjIeuYdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle 시간 좀 걸림\n",
        "tf_image = next(iter(dataset))\n",
        "tf_images.shape"
      ],
      "metadata": {
        "id": "4wXJ8HPQvOhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle 이전에 첫 번째 이미지와 지금은 다른 이미지로 shuffle 된것 확인\n",
        "plt.imshow(tf_images[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "blS8gPo5vVN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#B.라벨정보 포함한 이미지 데이터셋 만들기(수작업 필요)\n",
        "- 이미지 데이터만 만들었으나, 지도학습을 위해선 이미지 라벨링이 필요함\n",
        "\n",
        "- Data Preprocess : 아래 작업을 손수 작성해야 함\n",
        "1. glob이용하여 이미지 패스 읽기\n",
        "2. shuffle\n",
        "3. Train/Test 비율로 나누기\n",
        "4. 이미지 라벨링 만들기\n",
        "5. from_tensor_slices >map > cache > batch > prefetch 파이프라인 사용하여 이미지/라벨링 데이터셋 만들기\n"
      ],
      "metadata": {
        "id": "0BhUqSH2vntR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tunning\n",
        "num_epochs =10\n",
        "batch_size = 32\n",
        "\n",
        "learning_rate = 0.001\n",
        "dropout = 0.5\n",
        "input_shape = (227, 227, 3) #사이즈 확인\n",
        "num_classes = 2 #positive, Negative"
      ],
      "metadata": {
        "id": "h5iMmE88vnKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#glob를 통해 이미지 패스 읽어오기\n",
        "image_paths_list = glob('./IMAGE/*/*.jpg')\n",
        "print(len(image_paths_list))\n",
        "\n",
        "image_paths = np.random.permutataion(image_paths_list)\n",
        "image_paths[:10]"
      ],
      "metadata": {
        "id": "AoMwrwH9wlze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 :2 비율로 Train, Test 이미지셋 나누기\n",
        "TRAIN_SIZE = int(len(image_paths) * 0.8) #전체 row 수의 0.8배만큼을 Trian 나머지를 test\n",
        "print(TRAIN_SIZE)\n",
        "train_paths = image_paths[:TRAIN_SIZE]\n",
        "test_paths = image_paths[TRAIN_SIZE:]"
      ],
      "metadata": {
        "id": "4fIwiTJnw0k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_paths), len(test_paths)"
      ],
      "metadata": {
        "id": "Ijj2nhuHwzlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Positive, Negative 폴더 이름 반환하는 함수\n",
        "#EX) ./IMAGE?Negative07269.jog --> /Negative 가져오는 함수 만들기\n",
        "def get_class_name(path):\n",
        "  name = os.path.dirname(path).split('/')[-1] #폴더명\n",
        "  return name"
      ],
      "metadata": {
        "id": "eSoLoIlu2m8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_class_name 함수 정상 동작 여부 확인\n",
        "for path in train_paths[:4]:\n",
        "  print(path, get_class_name(path))"
      ],
      "metadata": {
        "id": "pH2ebft828ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class 이름 만들기\n",
        "train_labes = [get_class_name{path} for path in train_paths]\n",
        "class_names = np.unique(train_labes)\n",
        "class_names"
      ],
      "metadata": {
        "id": "GvoOa74b3GZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원핫 인코딩 간단 변환 예제 (한번 알아보기)\n",
        "print('Negative' == np.array(['Negative', 'Positve']))\n",
        "print(('Negative' == np.array(['Negative', 'Positve'])).astype(int))"
      ],
      "metadata": {
        "id": "h5uwBXOz3ynX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파일  패스에서 'Negative', 'Postive' 폴더부분을 읽고\n",
        "# class_name 과 비교해서 (numpy broadcasting) onehot 만들어 리턴\n",
        "\n",
        "def get_label(path):\n",
        "  label_name = tf.strings.split(path, '/')[-2]\n",
        "  onehot = tf.cast(label_name == calss_names , tf.unit8) #원 핫 인코딩\n",
        "  # return tf.argmax(onehot) , 이번에는 원핫이 아닌 라벨 번호로 함\n",
        "  return onehot #이번에는 onehot 으로"
      ],
      "metadata": {
        "id": "UHh3cUuO4GMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_label(path):\n",
        "  gfile = tf.io.read_file(path)\n",
        "  image = tf.io.decode_image(gfile)\n",
        "  image = tf.cast(image, tf.float32) / 255. #rescale\n",
        "\n",
        "  label = get_label(path)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "2oO6tCnh4GJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 변환 처리: 여기에서는 사용하지 않음\n",
        "def image_preprocess(image, label):\n",
        "  image = tf.image.random_flip_up_down(image)\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "Gshe4BXx6F-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load image label함수 잘 동작하는지 확인하기\n",
        "load_image_label('./IMAGE/Negative/00472.jpg')"
      ],
      "metadata": {
        "id": "eg0_h1TZ6bPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#병렬화\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "D21VNrF-6nHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensor_slices > map > cache > batch > shuffle > prefetch 형태로 사용\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
        "train_dataset = train_dataset.map(load_image_label, num_parallel_calls = AUTOTUNE)\n",
        "#train_dataset = train_dataset.map(image_preprocess, num_parallel_calls = AUTOTUNE)\n",
        "train_dataset = traIn_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 512)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.prefetch(buffer_size = AUTOTUNE)\n",
        "#"
      ],
      "metadata": {
        "id": "pDngynd7HR-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from_tensor_slices > map > cache > batch >prefetch 형태로 사용\n",
        "#test set은 shuffle 하지 않음\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
        "test_dataset = test_dataset.map(load_image_label, num_parallel_calls = AUTOTUNE)\n",
        "test_dataset = test_dataset.cache()\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "DHF_j1eZID0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#샘플 이미지 확인\n",
        "i = 0\n",
        "for batch_img, batch_label in train_dataset.stake(1):\n",
        "  if i == 0:\n",
        "    print(batch_img[i].shape)\n",
        "    plt.imshow(batch_img[i])\n",
        "  i = i + 1"
      ],
      "metadata": {
        "id": "w843XA3xcDM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build 모델\n",
        "#우선 Functional API 모델 정의\n",
        "inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "net = tf.keras.layers.Conv2D(32, (3,3), padding = 'SAME')(inputs) #227 * 227 * 32\n",
        "net = tf.keras.layers.Activation('relu')(net)\n",
        "net = tf.keras.layers.Conv2D(32,(3,3), padding = 'SAME')(net) #227 * 227 * 32\n",
        "net = tf.keras.layers.Activation('relu')(net)\n",
        "net = tf.keras.layers.MaxPooling2D(pool_size = (2 , 2))(net) #113 * 113 * 32\n",
        "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
        "\n",
        "net = tf.keras.layers.Conv2D(64, (3,3), padding = 'SAME')(net) #113 * 113 * 64\n",
        "net = tf.keras.layers.Activation('relu')(net)\n",
        "net = tf.keras.layers.Conv2D(64, (3,3), padding = 'SAME')(net) #113 * 113 * 64\n",
        "net = tf.keras.layers.Activation('relu')(net)\n",
        "net = tf.keras.layers.MaxPooling2D(pool_size = (2 , 2))(net) #56 *56 * 64\n",
        "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
        "\n",
        "net = tf.keras.layers.Flatten()(net)\n",
        "net = tf.keras.layers.Dense(512)(net)\n",
        "net = tf.keras.layers.Activation('relu')(net)\n",
        "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
        "net = tf.keras.layers.Dense(num_classes)(net)\n",
        "net = tf.keras.layers.Activation('softmax')(net)\n",
        "\n",
        "model = tf.keras.Model(inputs = inputs, outputs = net, name = 'Basic CNN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "2rZBUbrycZtz",
        "outputId": "27ca5795-f4f4-46a2-d4ea-109ea2ed3bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1945827853.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Build 모델\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#우선 Functional API 모델 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#227 * 227 * 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 컴파일\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "aIIfqUh1d5of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "1DntaUpEeJTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback : EarlyStopping , ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "#Early Stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode ='min', verbose =1, patience =3)\n",
        "\n",
        "#ModelCheckPoint\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath = checkpoint_path,\n",
        "                             save_weights_only = True,\n",
        "                             save_best_only = True,\n",
        "                             monitor = 'val_loss',\n",
        "                             verbose =1)\n",
        "\n",
        "\n",
        "#ReduceLROnPlateau :val_loss 가 2번 이상 감소되지 않으면 lr * factor = lr 새로운 lr로 변경해서 학습 진행\n",
        "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor = 0.5, patience =2, min_lr =0.0001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "3pDyOeoAeM1u",
        "outputId": "8f50c016-41de-434f-b753-f511e0520ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=my_checkpoint.ckpt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2060569852.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#ModelCheckPoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"my_checkpoint.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m checkpoint = ModelCheckpoint(filepath = checkpoint_path,\n\u001b[0m\u001b[1;32m     11\u001b[0m                              \u001b[0msave_weights_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                              \u001b[0msave_best_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;34m\"When using `save_weights_only=True` in `ModelCheckpoint`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;34m\", the filepath provided must end in `.weights.h5` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=my_checkpoint.ckpt"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습\n",
        "#에포크 10 배치사이즈 32 데이터 학습시간이 오래 걸려 take(10)활용함 ...정확도 50도 안됨 ㅜㅜ\n",
        "#나중에 take(10) 뺴도록해\n",
        "history = model.fit(\n",
        "    train_dataset.take(10),\n",
        "    validation_data = (test_dataset.take(10)),\n",
        "    epochs =5,\n",
        "    batch_size =batch_size,\n",
        "    callbacks = [es,chechpoint, lrReducer]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "NPaa0PEqg0NW",
        "outputId": "7a86a79e-8ce4-45a0-a9d4-20ac4f32e63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-1219831619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#에포크 10 배치사이즈 32 데이터 학습시간이 오래 걸려 take(10)활용함 ...정확도 50도 안됨 ㅜㅜ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#성능 그래프\n",
        "history.history.keys()\n",
        "plt.plot(history.history['accuracy']m label =\"Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label= 'Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accurcay')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ivy1Ejp9hYTX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "d055eaec-2cb7-448e-bd4b-a00e5d8edd8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-1266072219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#성능 그래프\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#너무 적은 데이터로 학습하니 성능이 50% 정도 나옴\n",
        "plt.figure(figsize=(16,30))\n",
        "for batch_img, batch_label in test_dataset.take(1):\n",
        "  for i in ragne(len(batch_img)):\n",
        "    pred = model.predict(batch_img[i].numpy().reshape(-1, 227, 227 , 3))\n",
        "    pred_t = np.argmax(pred)\n",
        "    plt.subplot(10, 5, i+1)\n",
        "    plt.title(f'True Value:{np.argmax(batch_label[i])}, Pred Value: {pred_t}')\n",
        "    plt.imshow(batch_img[i])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "CHjM0V1OmdtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2wFyn_-rXo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 배운 내용 정리\n",
        "1. glob과 Dataset from_tensor_slices 활용해서 이미지 Dataset 만들어 봄\n",
        "2. glob, from_tensor_slices 함수를 이용하여 필요한 데이터를 Datasetdksdmfh dlfrdjdhrl\n",
        "3. 이미지 파일명 읽어와 화면에 보여주기 : tf.io.read_file, tf.io.decode_image, plt.imshow\n",
        "4. Tensorflow Dataset활용해서 읽어온 데이터를 파이프라인을 통하여 shuffle, batch, cache, prefetch된 Dataset을 만들 수 있다.\n",
        "5. 모델 학습을 위해서는 라벨 정보도 필요하므로\n",
        "6. 라벨 정보 포함해서 glob, from_tensor_slices, Pipeline(map, cache, prefetch된 Dataset을 만들 수 있다.)\n",
        "7. 하지만 glob, from_tensor_slices, Pipeline, 라벨 코딩등 굉장히 번거롭고 수작업이 필요했으며\n",
        "8. 이런 수작업을 쉽게 해줄 고수준의 API가 있음..."
      ],
      "metadata": {
        "id": "5ICSQpwDr-gx"
      }
    }
  ]
}